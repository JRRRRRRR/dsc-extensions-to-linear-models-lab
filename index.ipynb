{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use AIC and BIC to select the best value for the regularization parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ames.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['LotArea', 'OverallQual', 'OverallCond', 'TotalBsmtSF',\n",
    "         '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'TotRmsAbvGrd',\n",
    "         'GarageArea', 'Fireplaces', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a baseline housing data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we imported the Ames housing data and grabbed a subset of the data to use in this analysis.\n",
    "\n",
    "Next steps:\n",
    "\n",
    "- Split the data into target (`y`) and predictors (`X`) -- ensure these both are DataFrames \n",
    "- Scale all the predictors using `scale`. Convert these scaled features into a DataFrame \n",
    "- Build at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation (set `random_state` to 1) and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "y = df['SalePrice']\n",
    "X = df.drop(columns='SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scale(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7524751004088887"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression = LinearRegression()\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression, X_scaled, y, scoring='r2', cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold cross-validation and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interactions: [('OverallQual', 'TotRmsAbvGrd', 0.77), ('OverallQual', 'GarageArea', 0.764), ('OverallQual', '2ndFlrSF', 0.758), ('2ndFlrSF', 'GrLivArea', 0.756), ('2ndFlrSF', 'TotRmsAbvGrd', 0.756), ('OverallQual', 'Fireplaces', 0.754), ('OverallCond', 'TotalBsmtSF', 0.754)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "combinations = list(combinations(X.columns, 2))\n",
    "\n",
    "interactions = []\n",
    "data = X_scaled.copy()\n",
    "for comb in combinations:\n",
    "    data['interaction'] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring='r2', cv=crossvalidation))\n",
    "    if score > baseline: \n",
    "        interactions.append((comb[0], comb[1], round(score, 3)))\n",
    "            \n",
    "print('Top 7 interactions: %s' %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\", where var1 and var2 are the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>OverallQual_2ndFlrSF</th>\n",
       "      <th>OverallQual_TotRmsAbvGrd</th>\n",
       "      <th>OverallQual_GarageArea</th>\n",
       "      <th>OverallQual_Fireplaces</th>\n",
       "      <th>OverallCond_TotalBsmtSF</th>\n",
       "      <th>OverallCond_1stFlrSF</th>\n",
       "      <th>2ndFlrSF_GrLivArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-0.459303</td>\n",
       "      <td>-0.793434</td>\n",
       "      <td>1.161852</td>\n",
       "      <td>0.370333</td>\n",
       "      <td>0.912210</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>-0.951226</td>\n",
       "      <td>0.756922</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>0.228669</td>\n",
       "      <td>-0.619704</td>\n",
       "      <td>0.237551</td>\n",
       "      <td>0.410364</td>\n",
       "      <td>0.430272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>-0.071836</td>\n",
       "      <td>2.179628</td>\n",
       "      <td>0.466465</td>\n",
       "      <td>0.257140</td>\n",
       "      <td>-0.795163</td>\n",
       "      <td>-0.482512</td>\n",
       "      <td>-0.318683</td>\n",
       "      <td>-0.060731</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.057121</td>\n",
       "      <td>0.022893</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>-0.043137</td>\n",
       "      <td>1.016720</td>\n",
       "      <td>0.560470</td>\n",
       "      <td>0.383676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073480</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-0.313369</td>\n",
       "      <td>-0.627826</td>\n",
       "      <td>1.189351</td>\n",
       "      <td>0.515013</td>\n",
       "      <td>-0.318683</td>\n",
       "      <td>0.631726</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.774837</td>\n",
       "      <td>-0.207616</td>\n",
       "      <td>0.411557</td>\n",
       "      <td>0.391210</td>\n",
       "      <td>0.162074</td>\n",
       "      <td>0.324712</td>\n",
       "      <td>0.612531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.096897</td>\n",
       "      <td>0.651479</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-0.687324</td>\n",
       "      <td>-0.521734</td>\n",
       "      <td>0.937276</td>\n",
       "      <td>0.383659</td>\n",
       "      <td>0.296763</td>\n",
       "      <td>0.790804</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.610616</td>\n",
       "      <td>0.193335</td>\n",
       "      <td>0.515193</td>\n",
       "      <td>0.391210</td>\n",
       "      <td>0.355484</td>\n",
       "      <td>0.269840</td>\n",
       "      <td>0.359595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.375148</td>\n",
       "      <td>1.374795</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.199680</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>1.617877</td>\n",
       "      <td>1.299326</td>\n",
       "      <td>1.527656</td>\n",
       "      <td>1.698485</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>2.224249</td>\n",
       "      <td>2.100214</td>\n",
       "      <td>2.335068</td>\n",
       "      <td>0.825557</td>\n",
       "      <td>-0.103274</td>\n",
       "      <td>0.023590</td>\n",
       "      <td>2.102150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n",
       "0 -0.207142     0.651479    -0.517200    -0.459303 -0.793434  1.161852   \n",
       "1 -0.091886    -0.071836     2.179628     0.466465  0.257140 -0.795163   \n",
       "2  0.073480     0.651479    -0.517200    -0.313369 -0.627826  1.189351   \n",
       "3 -0.096897     0.651479    -0.517200    -0.687324 -0.521734  0.937276   \n",
       "4  0.375148     1.374795    -0.517200     0.199680 -0.045611  1.617877   \n",
       "\n",
       "   GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  OverallQual_2ndFlrSF  \\\n",
       "0   0.370333      0.912210    0.351000   -0.951226              0.756922   \n",
       "1  -0.482512     -0.318683   -0.060731    0.600495              0.057121   \n",
       "2   0.515013     -0.318683    0.631726    0.600495              0.774837   \n",
       "3   0.383659      0.296763    0.790804    0.600495              0.610616   \n",
       "4   1.299326      1.527656    1.698485    0.600495              2.224249   \n",
       "\n",
       "   OverallQual_TotRmsAbvGrd  OverallQual_GarageArea  OverallQual_Fireplaces  \\\n",
       "0                  0.594286                0.228669               -0.619704   \n",
       "1                  0.022893                0.004363               -0.043137   \n",
       "2                 -0.207616                0.411557                0.391210   \n",
       "3                  0.193335                0.515193                0.391210   \n",
       "4                  2.100214                2.335068                0.825557   \n",
       "\n",
       "   OverallCond_TotalBsmtSF  OverallCond_1stFlrSF  2ndFlrSF_GrLivArea  \n",
       "0                 0.237551              0.410364            0.430272  \n",
       "1                 1.016720              0.560470            0.383676  \n",
       "2                 0.162074              0.324712            0.612531  \n",
       "3                 0.355484              0.269840            0.359595  \n",
       "4                -0.103274              0.023590            2.102150  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter = X_scaled.copy()\n",
    "for i in interactions[:7]:\n",
    "    df_inter['{}_{}'.format(i[0], i[1])] = df_inter[i[0]] * df_inter[i[1]]\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('OverallQual', 2, 0.781)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 polynomials: [('GrLivArea', 4, 0.807), ('GrLivArea', 3, 0.788), ('OverallQual', 2, 0.781), ('OverallQual', 3, 0.779), ('OverallQual', 4, 0.779), ('2ndFlrSF', 3, 0.775), ('2ndFlrSF', 2, 0.771), ('2ndFlrSF', 4, 0.771), ('GarageArea', 4, 0.767), ('GarageArea', 3, 0.758)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "polynomials = []\n",
    "for col in X.columns:\n",
    "    for degree in [2, 3, 4]:\n",
    "        data = X_scaled.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X_transformed = poly.fit_transform(X[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X_transformed)], axis=1)\n",
    "        score = np.mean(cross_val_score(regression, data, y, scoring='r2', cv=crossvalidation))\n",
    "        if score > baseline: polynomials.append((col, degree, round(score, 3)))\n",
    "print('Top 10 polynomials: %s' %sorted(polynomials, key=lambda poly: poly[2], reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum $R^2$ possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "OverallQual     0.781\n",
       "OverallCond     0.753\n",
       "2ndFlrSF        0.775\n",
       "GrLivArea       0.807\n",
       "TotRmsAbvGrd    0.753\n",
       "GarageArea      0.767\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "polynom = pd.DataFrame(polynomials)\n",
    "polynom.groupby([0], sort=False)[2].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best $R^2$ compared to the baseline model. For each of the two features, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for col in ['OverallQual', 'GrLivArea']:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X_transformed = poly.fit_transform(X[[col]])\n",
    "    colnames= [col, col + '_' + '2',  col + '_' + '3', col + '_' + '4']\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1), pd.DataFrame(X_transformed, columns=colnames)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>OverallQual_2ndFlrSF</th>\n",
       "      <th>OverallQual_TotRmsAbvGrd</th>\n",
       "      <th>...</th>\n",
       "      <th>OverallCond_1stFlrSF</th>\n",
       "      <th>2ndFlrSF_GrLivArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallQual_2</th>\n",
       "      <th>OverallQual_3</th>\n",
       "      <th>OverallQual_4</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GrLivArea_2</th>\n",
       "      <th>GrLivArea_3</th>\n",
       "      <th>GrLivArea_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.207142</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-0.459303</td>\n",
       "      <td>-0.793434</td>\n",
       "      <td>1.161852</td>\n",
       "      <td>0.912210</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>-0.951226</td>\n",
       "      <td>0.756922</td>\n",
       "      <td>0.594286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410364</td>\n",
       "      <td>0.430272</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>2924100.0</td>\n",
       "      <td>5.000211e+09</td>\n",
       "      <td>8.550361e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.091886</td>\n",
       "      <td>2.179628</td>\n",
       "      <td>0.466465</td>\n",
       "      <td>0.257140</td>\n",
       "      <td>-0.795163</td>\n",
       "      <td>-0.318683</td>\n",
       "      <td>-0.060731</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.057121</td>\n",
       "      <td>0.022893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560470</td>\n",
       "      <td>0.383676</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>1296.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>1592644.0</td>\n",
       "      <td>2.009917e+09</td>\n",
       "      <td>2.536515e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.073480</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-0.313369</td>\n",
       "      <td>-0.627826</td>\n",
       "      <td>1.189351</td>\n",
       "      <td>-0.318683</td>\n",
       "      <td>0.631726</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.774837</td>\n",
       "      <td>-0.207616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324712</td>\n",
       "      <td>0.612531</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>3189796.0</td>\n",
       "      <td>5.696976e+09</td>\n",
       "      <td>1.017480e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.096897</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>-0.687324</td>\n",
       "      <td>-0.521734</td>\n",
       "      <td>0.937276</td>\n",
       "      <td>0.296763</td>\n",
       "      <td>0.790804</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>0.610616</td>\n",
       "      <td>0.193335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269840</td>\n",
       "      <td>0.359595</td>\n",
       "      <td>7.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>2948089.0</td>\n",
       "      <td>5.061869e+09</td>\n",
       "      <td>8.691229e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.375148</td>\n",
       "      <td>-0.517200</td>\n",
       "      <td>0.199680</td>\n",
       "      <td>-0.045611</td>\n",
       "      <td>1.617877</td>\n",
       "      <td>1.527656</td>\n",
       "      <td>1.698485</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>2.224249</td>\n",
       "      <td>2.100214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023590</td>\n",
       "      <td>2.102150</td>\n",
       "      <td>8.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>4831204.0</td>\n",
       "      <td>1.061899e+10</td>\n",
       "      <td>2.334053e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  TotRmsAbvGrd  \\\n",
       "0 -0.207142    -0.517200    -0.459303 -0.793434  1.161852      0.912210   \n",
       "1 -0.091886     2.179628     0.466465  0.257140 -0.795163     -0.318683   \n",
       "2  0.073480    -0.517200    -0.313369 -0.627826  1.189351     -0.318683   \n",
       "3 -0.096897    -0.517200    -0.687324 -0.521734  0.937276      0.296763   \n",
       "4  0.375148    -0.517200     0.199680 -0.045611  1.617877      1.527656   \n",
       "\n",
       "   GarageArea  Fireplaces  OverallQual_2ndFlrSF  OverallQual_TotRmsAbvGrd  \\\n",
       "0    0.351000   -0.951226              0.756922                  0.594286   \n",
       "1   -0.060731    0.600495              0.057121                  0.022893   \n",
       "2    0.631726    0.600495              0.774837                 -0.207616   \n",
       "3    0.790804    0.600495              0.610616                  0.193335   \n",
       "4    1.698485    0.600495              2.224249                  2.100214   \n",
       "\n",
       "   ...  OverallCond_1stFlrSF  2ndFlrSF_GrLivArea  OverallQual  OverallQual_2  \\\n",
       "0  ...              0.410364            0.430272          7.0           49.0   \n",
       "1  ...              0.560470            0.383676          6.0           36.0   \n",
       "2  ...              0.324712            0.612531          7.0           49.0   \n",
       "3  ...              0.269840            0.359595          7.0           49.0   \n",
       "4  ...              0.023590            2.102150          8.0           64.0   \n",
       "\n",
       "   OverallQual_3  OverallQual_4  GrLivArea  GrLivArea_2   GrLivArea_3  \\\n",
       "0          343.0         2401.0     1710.0    2924100.0  5.000211e+09   \n",
       "1          216.0         1296.0     1262.0    1592644.0  2.009917e+09   \n",
       "2          343.0         2401.0     1786.0    3189796.0  5.696976e+09   \n",
       "3          343.0         2401.0     1717.0    2948089.0  5.061869e+09   \n",
       "4          512.0         4096.0     2198.0    4831204.0  1.061899e+10   \n",
       "\n",
       "    GrLivArea_4  \n",
       "0  8.550361e+12  \n",
       "1  2.536515e+12  \n",
       "2  1.017480e+13  \n",
       "3  8.691229e+12  \n",
       "4  2.334053e+13  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the $R^2$ of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8272489801539284"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "full_model = np.mean(cross_val_score(regression, df_inter, y, scoring='r2', cv=crossvalidation))\n",
    "full_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You learned that when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter $alpha$ of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here \n",
    "model_bic = LassoLarsIC(criterion='bic')\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_\n",
    "\n",
    "model_aic = LassoLarsIC(criterion='aic')\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_\n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for the regularization parameter according to AIC and BIC, and compare $R^2$ and RMSE using train-test split. Compare with the baseline model.\n",
    "\n",
    "Remember, you can find the Root Mean Squared Error (RMSE) by setting `squared=False` inside the function (see [the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)), and the RMSE returns values that are in the same units as our target - so we can see how far off our predicted sale prices are in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21.3\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-Squared: 0.7478270652928448\n",
      "Test R-Squared: 0.8120708166668685\n",
      "Training RMSE: 39424.15590381302\n",
      "Test RMSE: 35519.17035590486\n"
     ]
    }
   ],
   "source": [
    "# Split X_scaled and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=1)\n",
    "\n",
    "# Code for baseline model\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "\n",
    "# Print R-Squared and RMSE\n",
    "print('Training R-Squared:', linreg_all.score(X_train, y_train))\n",
    "print('Test R-Squared:', linreg_all.score(X_test, y_test))\n",
    "## sklearn new version doesn't have squared argument, therefore, i use np.sqrt here\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(y_train, linreg_all.predict(X_train))))\n",
    "print('Test RMSE:', np.sqrt(mean_squared_error(y_test, linreg_all.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-Squared: 0.8440644772749533\n",
      "Test R-Squared: 0.8604336173535994\n",
      "Training RMSE: 31001.713430916676\n",
      "Test RMSE: 30609.491227226074\n"
     ]
    }
   ],
   "source": [
    "# Split df_inter and y into training and test sets\n",
    "# Set random_state to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_inter, y, random_state=1)\n",
    "\n",
    "# Code for lasso with alpha from AIC\n",
    "lasso = Lasso(alpha= model_aic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R-Squared and RMSE\n",
    "print('Training R-Squared:', lasso.score(X_train, y_train))\n",
    "print('Test R-Squared:', lasso.score(X_test, y_test))\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(y_train, lasso.predict(X_train))))\n",
    "print('Test RMSE:', np.sqrt(mean_squared_error(y_test, lasso.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R-Squared: 0.8440343933696247\n",
      "Test R-Squared: 0.8603967471627407\n",
      "Training RMSE: 31004.70379391047\n",
      "Test RMSE: 30613.53411791394\n"
     ]
    }
   ],
   "source": [
    "# Code for lasso with alpha from BIC\n",
    "lasso = Lasso(alpha= model_bic.alpha_) \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Print R-Squared and RMSE\n",
    "print('Training R-Squared:', lasso.score(X_train, y_train))\n",
    "print('Test R-Squared:', lasso.score(X_test, y_test))\n",
    "print('Training RMSE:', np.sqrt(mean_squared_error(y_train, lasso.predict(X_train))))\n",
    "print('Test RMSE:', np.sqrt(mean_squared_error(y_test, lasso.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso path\n",
    "\n",
    "From this section, you know that when using Lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Ames housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
